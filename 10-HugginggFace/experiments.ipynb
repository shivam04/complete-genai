{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hugging Face x LangChain : A new partner package in LangChain\n",
    "langchain_huggingface, a partner package in LangChain jointly maintained by Hugging Face and LangChain. This new Python package is designed to bring the power of the latest development of Hugging Face into LangChain and keep it up to date."
   ],
   "id": "709efc5e46950f56"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace",
   "id": "3984622c089d2fce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    task=\"conversational\",   # ðŸ”¥ THIS is required\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.7,\n",
    "    huggingfacehub_api_token=os.getenv(\"HF_TOKEN\"),\n",
    ")\n",
    "llm"
   ],
   "id": "9129a0a926273b43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chat = ChatHuggingFace(llm=llm)\n",
    "chat"
   ],
   "id": "a6b312fe30c51a9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chat.invoke(\"What is machine learning\")",
   "id": "76fb3ef2b5205ac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chat.invoke(\"What is generative AI \")",
   "id": "e991dbfd37c59aa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "repo_id=\"google/gemma-2-9b\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    task=\"conversational\",   # ðŸ”¥ THIS is required\n",
    "    max_new_tokens=150,\n",
    "    temperature=0.7,\n",
    "    huggingfacehub_api_token=os.getenv(\"HF_TOKEN\"),\n",
    ")\n",
    "llm"
   ],
   "id": "3b0ac917ee71439a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm.invoke(\"What is machine learning\")",
   "id": "7472aedbfb6d7264",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "template=\"\"\"\n",
    "Question:{question}\n",
    "Answer:Lets think step by step.\n",
    "\"\"\"\n",
    "template"
   ],
   "id": "88be4e4d3c6a1d4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt=PromptTemplate(template=template,input_variables=[\"question\"])\n",
    "print(prompt)"
   ],
   "id": "34e2936b01e193eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "llm_chain = prompt | llm\n",
    "llm_chain"
   ],
   "id": "a05913115c1a9322",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from langchain_community.embeddings import HuggingFaceEmbeddings",
   "id": "e4809694719475db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ],
   "id": "40f931730b8735ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embedding = hf.embed_query(\"hi this is shivam\")\n",
    "embedding"
   ],
   "id": "ad3f0a1ba2e17c03",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
