{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ],
   "id": "5dbe55577ec1a766"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:46:05.533014Z",
     "start_time": "2026-01-07T16:46:05.514564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "2d03a2286f5a0f3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:46:05.895816Z",
     "start_time": "2026-01-07T16:46:05.892453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ],
   "id": "9cb45490c164a2d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:46:10.106257Z",
     "start_time": "2026-01-07T16:46:06.464549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ],
   "id": "19b7b1421b9bde3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x0000021414303E00> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002141483C980> root_client=<openai.OpenAI object at 0x0000021414301010> root_async_client=<openai.AsyncOpenAI object at 0x000002141483C6E0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:46:34.370854Z",
     "start_time": "2026-01-07T16:46:25.117835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ],
   "id": "2e9785e37d66dafe",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:47:01.493263Z",
     "start_time": "2026-01-07T16:47:01.488427Z"
    }
   },
   "cell_type": "code",
   "source": "print(result)",
   "id": "c4c65e2b86560ef9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence technologies that are designed to generate new content, such as text, images, music, or even code, by learning from existing data. Unlike traditional AI, which is often used to analyze or categorize data, generative AI creates new data that is similar to its training dataset.\\n\\nKey components and techniques used in generative AI include:\\n\\n1. **Neural Networks**: These are the backbone of generative models. Specifically, architectures such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer models are commonly used in generative AI.\\n\\n2. **Generative Adversarial Networks (GANs)**: This technique involves two neural networks—a generator and a discriminator—that are trained simultaneously. The generator attempts to create data that is indistinguishable from real data, while the discriminator tries to differentiate between real and generated data.\\n\\n3. **Variational Autoencoders (VAEs)**: VAEs are a type of neural network used for generating similar but new data. They encode input data into a latent space and then decode from this space to reconstruct the data, allowing for the generation of new outputs by sampling from the latent space.\\n\\n4. **Transformers**: Models like GPT (Generative Pre-trained Transformer) are based on transformer architecture and generate human-like text through the prediction of the next word in a sentence, trained on large volumes of text data.\\n\\nApplications of generative AI are vast and include areas such as:\\n\\n- **Content Creation**: Automatically generating text for articles, stories, and reports.\\n- **Art and Design**: Creating images, music, and visual content.\\n- **Data Augmentation**: Generating synthetic data for training other machine learning models to improve their performance.\\n- **Drug Discovery**: Creating novel chemical compounds.\\n\\nGenerative AI has significant implications across multiple industries by enabling the creation of original content and aiding in innovation and problem-solving. However, it also brings challenges related to ethics, authenticity, and security, such as the creation of deepfakes or the generation of misleading information.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 426, 'prompt_tokens': 13, 'total_tokens': 439, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-CvQxwdO7oATOTed5g4P4RxyDgKkyW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b995a-3763-7442-b1bc-e14065da7b1a-0' usage_metadata={'input_tokens': 13, 'output_tokens': 426, 'total_tokens': 439, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:47:04.704355Z",
     "start_time": "2026-01-07T16:47:04.611173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ],
   "id": "65cb94bc2089ffa5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:47:24.722166Z",
     "start_time": "2026-01-07T16:47:21.242199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## chain\n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ],
   "id": "b732b72ed599a1fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a platform designed to enhance the development and management of AI applications built with large language models (LLMs). It offers a suite of tools that focus on improving the robustness, reliability, and overall performance of these applications. Langsmith provides features such as debugging capabilities, testing environments, and monitoring tools that allow developers to fine-tune their applications and ensure they meet the desired criteria. By offering these functionalities, Langsmith aims to streamline the development process, facilitate better version control, and enhance the iterative testing of applications utilizing LLMs, making it easier for developers to create sophisticated and dependable AI-driven solutions.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 123, 'prompt_tokens': 33, 'total_tokens': 156, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_deacdd5f6f', 'id': 'chatcmpl-CvQypP9zR0ib3pqWuJZKkMioLtTh0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b995b-12a7-72f3-8730-dca8c8b9d381-0' usage_metadata={'input_tokens': 33, 'output_tokens': 123, 'total_tokens': 156, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:47:41.291114Z",
     "start_time": "2026-01-07T16:47:41.286047Z"
    }
   },
   "cell_type": "code",
   "source": "type(response)",
   "id": "a52ed577c9f78d70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T16:47:59.259724Z",
     "start_time": "2026-01-07T16:47:55.794455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ],
   "id": "8b7d10be008a831c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a development tool designed for building applications around large language models (LLMs). It acts as a complement to Langchain, a framework for developing applications powered by language models. Langsmith provides capabilities for testing, debugging, and monitoring LLM applications, allowing developers to more effectively track the performance and behavior of their models and applications. It is designed to streamline the process of deploying complex LLM-driven workflows by offering an integrated environment that supports seamless iteration and refinement of application features.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "395e0667aee7cc33"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
